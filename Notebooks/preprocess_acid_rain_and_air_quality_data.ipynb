{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import Rbf\n",
    "os.chdir('/Users/zeqinhuang/Documents/paper/acid_rain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with air quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_stn = pd.read_csv('ACID_RAIN_DATA/air_quality_station.csv',header=0)\n",
    "aq_stn_name1 = {aq_stn[aq_stn['Station_Name']==sn]['CN_name'].values[0]:sn for sn in aq_stn['Station_Name'].tolist()}\n",
    "aq_stn_name2 = {sn:aq_stn[aq_stn['Station_Name']==sn]['CN_name'].values[0] for sn in aq_stn['Station_Name'].tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_daily_max = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=2,header=0)\n",
    "SO2_month_mean = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=3,header=0)\n",
    "NO2_daily_max = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=5,header=0)\n",
    "NO2_month_mean = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=6,header=0)\n",
    "O3_daily_max = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=8,header=0)\n",
    "O3_month_mean = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=9,header=0)\n",
    "PM10_daily_max = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=11,header=0)\n",
    "PM10_month_mean = pd.read_excel('ACID_RAIN_DATA/GBA_aqi.xlsx',sheet_name=12,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_daily_max_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    SO2_daily_max_sn = SO2_daily_max.loc[SO2_daily_max['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        SO2_daily_max_sn = pd.Series(SO2_daily_max_sn.values.ravel(), index=pd.date_range('2015','2022',freq='m'))\n",
    "    else:\n",
    "        SO2_daily_max_sn = pd.Series(SO2_daily_max_sn.values.ravel(), index=pd.date_range('2006','2022',freq='m'))\n",
    "    SO2_daily_max_sn.name = aq_stn_name1[cn]\n",
    "    SO2_daily_max_all = pd.concat([SO2_daily_max_all, SO2_daily_max_sn],axis=1)\n",
    "SO2_daily_max_all = SO2_daily_max_all.replace(9999, None)\n",
    "\n",
    "SO2_month_mean_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    SO2_month_mean_sn = SO2_month_mean.loc[SO2_month_mean['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        SO2_month_mean_sn = pd.Series(SO2_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2015,2022) for m in range(1,13)])\n",
    "    else:\n",
    "        SO2_month_mean_sn = pd.Series(SO2_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2006,2022) for m in range(1,13)])\n",
    "    SO2_month_mean_sn.name = aq_stn_name1[cn]\n",
    "    SO2_month_mean_all = pd.concat([SO2_month_mean_all, SO2_month_mean_sn],axis=1)\n",
    "SO2_month_mean_all = SO2_month_mean_all.replace(9999, None)\n",
    "\n",
    "NO2_daily_max_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    NO2_daily_max_sn = NO2_daily_max.loc[NO2_daily_max['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        NO2_daily_max_sn = pd.Series(NO2_daily_max_sn.values.ravel(), index=pd.date_range('2015','2022',freq='m'))\n",
    "    else:\n",
    "        NO2_daily_max_sn = pd.Series(NO2_daily_max_sn.values.ravel(), index=pd.date_range('2006','2022',freq='m'))\n",
    "    NO2_daily_max_sn.name = aq_stn_name1[cn]\n",
    "    NO2_daily_max_all = pd.concat([NO2_daily_max_all, NO2_daily_max_sn],axis=1)\n",
    "NO2_daily_max_all = NO2_daily_max_all.replace(9999, None)\n",
    "\n",
    "NO2_month_mean_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    NO2_month_mean_sn = NO2_month_mean.loc[NO2_month_mean['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        NO2_month_mean_sn = pd.Series(NO2_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2015,2022) for m in range(1,13)])\n",
    "    else:\n",
    "        NO2_month_mean_sn = pd.Series(NO2_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2006,2022) for m in range(1,13)])\n",
    "    NO2_month_mean_sn.name = aq_stn_name1[cn]\n",
    "    NO2_month_mean_all = pd.concat([NO2_month_mean_all, NO2_month_mean_sn],axis=1)\n",
    "NO2_month_mean_all = NO2_month_mean_all.replace(9999, None)\n",
    "\n",
    "O3_daily_max_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    O3_daily_max_sn = O3_daily_max.loc[O3_daily_max['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        O3_daily_max_sn = pd.Series(O3_daily_max_sn.values.ravel(), index=pd.date_range('2015','2022',freq='m'))\n",
    "    else:\n",
    "        O3_daily_max_sn = pd.Series(O3_daily_max_sn.values.ravel(), index=pd.date_range('2006','2022',freq='m'))\n",
    "    O3_daily_max_sn.name = aq_stn_name1[cn]\n",
    "    O3_daily_max_all = pd.concat([O3_daily_max_all, O3_daily_max_sn],axis=1)\n",
    "O3_daily_max_all = O3_daily_max_all.replace(9999, None)\n",
    "\n",
    "O3_month_mean_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    O3_month_mean_sn = O3_month_mean.loc[O3_month_mean['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        O3_month_mean_sn = pd.Series(O3_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2015,2022) for m in range(1,13)])\n",
    "    else:\n",
    "        O3_month_mean_sn = pd.Series(O3_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2006,2022) for m in range(1,13)])\n",
    "    O3_month_mean_sn.name = aq_stn_name1[cn]\n",
    "    O3_month_mean_all = pd.concat([O3_month_mean_all, O3_month_mean_sn],axis=1)\n",
    "O3_month_mean_all = O3_month_mean_all.replace(9999, None)\n",
    "\n",
    "PM10_daily_max_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    PM10_daily_max_sn = PM10_daily_max.loc[PM10_daily_max['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        PM10_daily_max_sn = pd.Series(PM10_daily_max_sn.values.ravel(), index=pd.date_range('2015','2022',freq='m'))\n",
    "    else:\n",
    "        PM10_daily_max_sn = pd.Series(PM10_daily_max_sn.values.ravel(), index=pd.date_range('2006','2022',freq='m'))\n",
    "    PM10_daily_max_sn.name = aq_stn_name1[cn]\n",
    "    PM10_daily_max_all = pd.concat([PM10_daily_max_all, PM10_daily_max_sn],axis=1)\n",
    "PM10_daily_max_all = PM10_daily_max_all.replace(9999, None)\n",
    "\n",
    "PM10_month_mean_all = pd.DataFrame()\n",
    "for cn in aq_stn_name1.keys():\n",
    "    PM10_month_mean_sn = PM10_month_mean.loc[PM10_month_mean['监测子站']==cn].iloc[:,-12:]\n",
    "    if cn in ['磨碟沙','竹洞','西角','端芬','花果山','元朗','大潭山']:\n",
    "        PM10_month_mean_sn = pd.Series(PM10_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2015,2022) for m in range(1,13)])\n",
    "    else:\n",
    "        PM10_month_mean_sn = pd.Series(PM10_month_mean_sn.values.ravel(), index=[str(y)+'-'+str(m).zfill(2)+'-01' for y in range(2006,2022) for m in range(1,13)])\n",
    "    PM10_month_mean_sn.name = aq_stn_name1[cn]\n",
    "    PM10_month_mean_all = pd.concat([PM10_month_mean_all, PM10_month_mean_sn],axis=1)\n",
    "PM10_month_mean_all = PM10_month_mean_all.replace(9999, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_daily_max_all.to_csv('ACID_RAIN_DATA/SO2_daily_max_all_with_nan.csv')\n",
    "SO2_month_mean_all.to_csv('ACID_RAIN_DATA/SO2_month_mean_all_with_nan.csv')\n",
    "NO2_daily_max_all.to_csv('ACID_RAIN_DATA/NO2_daily_max_all_with_nan.csv')\n",
    "NO2_month_mean_all.to_csv('ACID_RAIN_DATA/NO2_month_mean_all_with_nan.csv')\n",
    "O3_daily_max_all.to_csv('ACID_RAIN_DATA/O3_daily_max_all_with_nan.csv')\n",
    "O3_month_mean_all.to_csv('ACID_RAIN_DATA/O3_month_mean_all_with_nan.csv')\n",
    "PM10_daily_max_all.to_csv('ACID_RAIN_DATA/PM10_daily_max_all_with_nan.csv')\n",
    "PM10_month_mean_all.to_csv('ACID_RAIN_DATA/PM10_month_mean_all_with_nan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with acid rain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "acid_rain_raw = pd.read_excel('ACID_RAIN_DATA/GBA_ar_raw.xlsx',sheet_name=0,header=1)\n",
    "acid_rain_raw.columns = ['City_code', 'Loc_city', 'CN_name', 'Station_name', 'Station_type', 'Year_s', 'Month_s', 'Day_s', 'Hour_s', 'Minute_s',\\\n",
    "       'Year_e', 'Month_e', 'Day_e', 'Hour_e', 'Minute_e', 'Rainfall_type', 'Rain_amount', 'pH', 'conductivity',\\\n",
    "       'SO42-', 'NO3-', 'F-', 'Cl-', 'NH4+', 'Ca2+', 'Mg2+', 'Na+', 'K+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_stn = pd.read_csv('ACID_RAIN_DATA/acid_rain_station.csv',header=0)\n",
    "ar_stn_name = ar_stn['Station_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ar_name in ar_stn_name:\n",
    "    acid_rain_an = acid_rain_raw.loc[acid_rain_raw['Station_name']==ar_name].copy()\n",
    "    acid_rain_an['time'] = acid_rain_an['Year_s'].astype(str) + '-' + acid_rain_an['Month_s'].astype(str).str.zfill(2) + '-' + acid_rain_an['Day_s'].astype(str).str.zfill(2)\n",
    "    del(acid_rain_an['Year_s'],acid_rain_an['Month_s'],acid_rain_an['Day_s'],acid_rain_an['Hour_s'],acid_rain_an['Minute_s'])\n",
    "    del(acid_rain_an['Year_e'],acid_rain_an['Month_e'],acid_rain_an['Day_e'],acid_rain_an['Hour_e'],acid_rain_an['Minute_e'])\n",
    "    acid_rain_an = acid_rain_an.replace({'城区':'Urban','郊区':'Rural'})\n",
    "    acid_rain_an.index = acid_rain_an['time'].values\n",
    "    acid_rain_an = acid_rain_an.groupby(['time']).mean()\n",
    "    acid_rain_an.to_csv('ACID_RAIN_DATA/acid_rain_' + ar_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpolate air quality data to each acid rain station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/questions/3104781/inverse-distance-weighted-idw-interpolation-with-python\n",
    "def scipy_idw(x, y, z, xi, yi):\n",
    "    interp = Rbf(x, y, z, function='linear')\n",
    "    return interp(xi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_points = pd.read_csv('ACID_RAIN_DATA/air_quality_station.csv',header=0,index_col=0)\n",
    "target_points = pd.read_csv('ACID_RAIN_DATA/acid_rain_station.csv',header=0,index_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_daily_max_all = pd.read_csv('ACID_RAIN_DATA/SO2_daily_max_all_with_nan.csv',header=0,index_col=0)\n",
    "SO2_month_mean_all = pd.read_csv('ACID_RAIN_DATA/SO2_month_mean_all_with_nan.csv',header=0,index_col=0)\n",
    "NO2_daily_max_all = pd.read_csv('ACID_RAIN_DATA/NO2_daily_max_all_with_nan.csv',header=0,index_col=0)\n",
    "NO2_month_mean_all = pd.read_csv('ACID_RAIN_DATA/NO2_month_mean_all_with_nan.csv',header=0,index_col=0)\n",
    "O3_daily_max_all = pd.read_csv('ACID_RAIN_DATA/O3_daily_max_all_with_nan.csv',header=0,index_col=0)\n",
    "O3_month_mean_all = pd.read_csv('ACID_RAIN_DATA/O3_month_mean_all_with_nan.csv',header=0,index_col=0)\n",
    "PM10_daily_max_all = pd.read_csv('ACID_RAIN_DATA/PM10_daily_max_all_with_nan.csv',header=0,index_col=0)\n",
    "PM10_month_mean_all = pd.read_csv('ACID_RAIN_DATA/PM10_month_mean_all_with_nan.csv',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_list = [SO2_daily_max_all, SO2_month_mean_all, NO2_daily_max_all, NO2_month_mean_all, O3_daily_max_all, O3_month_mean_all, PM10_daily_max_all, PM10_month_mean_all]\n",
    "for i in range(8):\n",
    "    aqi_i = aqi_list[i]\n",
    "    aqi_target_i = pd.DataFrame(columns=target_points.index)\n",
    "    for index, row in aqi_i.iterrows():\n",
    "        row = row.dropna()\n",
    "        source_points_i = source_points[source_points.index.isin(row.index)].copy()\n",
    "        source_points_i['value'] = row\n",
    "        x = source_points_i['LON']\n",
    "        y = source_points_i['LAT']\n",
    "        z = source_points_i['value']\n",
    "        target_points_i = target_points.copy()\n",
    "        xi = target_points_i['Lon']\n",
    "        yi = target_points_i['LAT']\n",
    "        zi = scipy_idw(x, y, z, xi, yi)\n",
    "        zi = pd.Series(zi, index=target_points.index.values)\n",
    "        zii = zi.to_frame().transpose()\n",
    "        zii.index = [index]\n",
    "        aqi_target_i = pd.concat([aqi_target_i,zii],axis=0)\n",
    "\n",
    "    if i == 0:\n",
    "        SO2_daily_max_interp = aqi_target_i\n",
    "    elif i == 1:\n",
    "        SO2_month_mean_interp = aqi_target_i\n",
    "    elif i == 2:\n",
    "        NO2_daily_max_interp = aqi_target_i\n",
    "    elif i == 3:\n",
    "        NO2_month_mean_interp = aqi_target_i\n",
    "    elif i == 4:\n",
    "        O3_daily_max_interp = aqi_target_i\n",
    "    elif i == 5:\n",
    "        O3_month_mean_interp = aqi_target_i\n",
    "    elif i == 6:\n",
    "        PM10_daily_max_interp = aqi_target_i\n",
    "    elif i == 7:\n",
    "        PM10_month_mean_interp = aqi_target_i\n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_daily_max_interp.to_csv('ACID_RAIN_DATA/SO2_daily_max_interp.csv')\n",
    "SO2_month_mean_interp.to_csv('ACID_RAIN_DATA/SO2_month_mean_interp.csv')\n",
    "NO2_daily_max_interp.to_csv('ACID_RAIN_DATA/NO2_daily_max_interp.csv')\n",
    "NO2_month_mean_interp.to_csv('ACID_RAIN_DATA/NO2_month_mean_interp.csv')\n",
    "O3_daily_max_interp.to_csv('ACID_RAIN_DATA/O3_daily_max_interp.csv')\n",
    "O3_month_mean_interp.to_csv('ACID_RAIN_DATA/O3_month_mean_interp.csv')\n",
    "PM10_daily_max_interp.to_csv('ACID_RAIN_DATA/PM10_daily_max_interp.csv')\n",
    "PM10_month_mean_interp.to_csv('ACID_RAIN_DATA/PM10_month_mean_interp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract meteorological data (from ERA5) for each arid station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/zeqinhuang/Documents/paper/acid_rain')\n",
    "variables = [\n",
    "    '2m_dewpoint_temperature', 'boundary_layer_height', '2m_temperature', 'mean_sea_level_pressure', 'vertical_velocity_850hpa',\n",
    "    'total_precipitation','total_cloud_cover','10m_v_component_of_wind','10m_u_component_of_wind','leaf_area_index_high_vegetation']\n",
    "# 大气边界层厚度直接决定了污染物扩散的有效空气体积和大气环境容量,大气边界层内的层结结构决定了污染物水平传输和垂直扩散的能力\n",
    "short_name = ['d2m','blh','t2m','msl','w', 'tp', 'tcc','v10','u10','lai_hv']\n",
    "var_names = dict(zip(variables, short_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_points = pd.read_csv('ACID_RAIN_DATA/acid_rain_station.csv',header=0,index_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in variables:\n",
    "    v_df = pd.DataFrame()\n",
    "    v_da = xr.open_dataarray('/Users/zeqinhuang/Documents/paper/acid_rain/ERA5_data/' + v + '_hourly_era5.nc')\n",
    "    if v == 'total_precipitation':\n",
    "        v_da = v_da.resample(time = '1D').sum('time')\n",
    "    else:\n",
    "        v_da = v_da.resample(time = '1D').mean('time')\n",
    "    for index, row in target_points.iterrows():\n",
    "        lon = round((row['Lon'] - int(row['Lon'])) / 0.25,0) * 0.25 + int(row['Lon'])\n",
    "        lat = round((row['LAT'] - int(row['LAT'])) / 0.25,0) * 0.25 + int(row['LAT'])\n",
    "        v_index = v_da.sel(longitude=slice(lon-0.25,lon+0.25),latitude=slice(lat+0.25,lat-0.25))\n",
    "        v_index = v_index.mean(dim=('longitude','latitude'))\n",
    "        v_df[index] = v_index\n",
    "    v_df.to_csv('/Users/zeqinhuang/Documents/paper/acid_rain/ERA5_data/' + v + '_for_acid_rain_stations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# match meteorological and aqi data with the acid rain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "stns = target_points.index\n",
    "\n",
    "for stn in stns:\n",
    "    acid_rain_stn = pd.read_csv('ACID_RAIN_DATA/acid_rain_' + stn + '.csv', header=0, index_col=0)\n",
    "    acid_rain_stn.index = pd.to_datetime(pd.Series(acid_rain_stn.index))\n",
    "    for v in variables: # match meteorological data\n",
    "        v_df = pd.read_csv('/Users/zeqinhuang/Documents/paper/acid_rain/ERA5_data/' + v + '_for_acid_rain_stations.csv',header=0,index_col=0)\n",
    "        time = pd.date_range('2005-01-01','2021-12-31',freq='D')\n",
    "        v_df.index = time\n",
    "        v_df_stn = v_df[stn]\n",
    "        v_df_stn.name = v\n",
    "        if v == 'total_precipitation':\n",
    "            v_df_stn = v_df_stn * 1000\n",
    "            v_df_stn_5d = v_df_stn.rolling(5).sum()\n",
    "            v_df_stn_5d.name = 'tp_5d'\n",
    "            v_df_stn_10d = v_df_stn.rolling(10).sum()\n",
    "            v_df_stn_10d.name = 'tp_10d'\n",
    "            v_df_stn_30d = v_df_stn.rolling(30).sum()\n",
    "            v_df_stn_30d.name = 'tp_30d'\n",
    "            acid_rain_stn = acid_rain_stn.join(v_df_stn)\n",
    "            acid_rain_stn = acid_rain_stn.join(v_df_stn_5d)\n",
    "            acid_rain_stn = acid_rain_stn.join(v_df_stn_10d)\n",
    "            acid_rain_stn = acid_rain_stn.join(v_df_stn_30d)\n",
    "        else:\n",
    "            acid_rain_stn = acid_rain_stn.join(v_df_stn)\n",
    "    acid_rain_stn = acid_rain_stn[acid_rain_stn.index.isin(pd.date_range('2006-01-01','2021-12-31',freq='D'))]\n",
    "    for aqi_n in ['SO2_daily_max','SO2_month_mean','NO2_daily_max','NO2_month_mean','O3_daily_max','O3_month_mean','PM10_daily_max','PM10_month_mean']:\n",
    "        aqi = pd.read_csv('ACID_RAIN_DATA/' + aqi_n + '_interp.csv',header=0,index_col=0)\n",
    "        dates = pd.date_range('2006-01-01','2021-12-31',freq='D')\n",
    "        months = pd.date_range('2006','2022',freq='M')\n",
    "        aqi.index = months\n",
    "        aqi_daily = aqi.reindex(dates, method='bfill')\n",
    "        aqi_daily_stn = aqi_daily[stn]\n",
    "        aqi_daily_stn.name = aqi_n\n",
    "        acid_rain_stn = acid_rain_stn.join(aqi_daily_stn)\n",
    "    acid_rain_stn.to_csv('/Users/zeqinhuang/Documents/paper/acid_rain/machine_learning_data/ml_data_' + stn + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_points = pd.read_csv('ACID_RAIN_DATA/acid_rain_station.csv',header=0,index_col=3)\n",
    "\n",
    "for stn in stns:\n",
    "    acid_rain_stn = pd.read_csv('/Users/zeqinhuang/Documents/paper/acid_rain/machine_learning_data/ml_data_' + stn + '.csv', header=0, index_col=0)\n",
    "    del(acid_rain_stn['City_code'])\n",
    "    acid_rain_stn['station'] = stn\n",
    "    acid_rain_stn['station_type'] = target_points['Station_Type'][stn]\n",
    "    acid_rain_stn['LON'] = target_points['Lon'][stn]\n",
    "    acid_rain_stn['LAT'] = target_points['LAT'][stn]\n",
    "    if stn == stns[0]:\n",
    "        acid_rain_all_stns = acid_rain_stn\n",
    "    else:\n",
    "        acid_rain_all_stns = pd.concat([acid_rain_all_stns, acid_rain_stn],axis=0)\n",
    "acid_rain_all_stns.to_csv('/Users/zeqinhuang/Documents/paper/acid_rain/machine_learning_data/ml_data_all_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tfMac38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85633838223fa24745b04ee2425a29866e58f21a05e261f135ffa2db214a5274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
